{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words in NLP\n",
    "\n",
    "### Context\n",
    "The Bag of Words (BoW) model is a fundamental technique in Natural Language Processing (NLP) for representing text data. It converts text into numerical feature vectors based on word frequency, enabling machine learning models to process textual information.\n",
    "\n",
    "#### Key Points:\n",
    "- **Purpose**: Represents text data as a fixed-size vector of word frequencies.\n",
    "- **Usage**:\n",
    "  - Commonly used in text classification, sentiment analysis, and information retrieval tasks.\n",
    "  - Provides a simple and effective method for feature extraction.\n",
    "- **How It Works**:\n",
    "  - A vocabulary of unique words is created from the text corpus.\n",
    "  - Each document is represented as a vector where each element corresponds to the frequency of a word in the document.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's implement the Bag of Words model for a small example corpus in Python. We will demonstrate both the standard BoW (using word frequencies) and Binary BoW (indicating word presence or absence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard BoW Vocabulary: ['hello' 'learning' 'machine' 'world']\n",
      "\n",
      "Standard BoW Feature Matrix:\n",
      "[[2 0 0 1]\n",
      " [0 1 1 0]\n",
      " [1 0 1 0]]\n",
      "\n",
      "Binary BoW Vocabulary: ['hello' 'learning' 'machine' 'world']\n",
      "\n",
      "Binary BoW Feature Matrix:\n",
      "[[1 0 0 1]\n",
      " [0 1 1 0]\n",
      " [1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text corpus\n",
    "corpus = [\n",
    "    \"hello world hello\",\n",
    "    \"machine learning\",\n",
    "    \"hello machine\"\n",
    "]\n",
    "\n",
    "# Step 1: Initialize the CountVectorizer for BoW\n",
    "vectorizer_bow = CountVectorizer()\n",
    "\n",
    "# Step 2: Fit the vectorizer to the corpus and transform it for standard BoW\n",
    "X_bow = vectorizer_bow.fit_transform(corpus)\n",
    "\n",
    "# Step 3: Retrieve the vocabulary and feature matrix for BoW\n",
    "vocabulary_bow = vectorizer_bow.get_feature_names_out()\n",
    "feature_matrix_bow = X_bow.toarray()\n",
    "\n",
    "print(\"Standard BoW Vocabulary:\", vocabulary_bow)\n",
    "print(\"\\nStandard BoW Feature Matrix:\")\n",
    "print(feature_matrix_bow)\n",
    "\n",
    "# Step 4: Initialize the CountVectorizer for Binary BoW (binary=True)\n",
    "vectorizer_binary_bow = CountVectorizer(binary=True)\n",
    "\n",
    "# Step 5: Fit the vectorizer to the corpus and transform it for Binary BoW\n",
    "X_binary_bow = vectorizer_binary_bow.fit_transform(corpus)\n",
    "\n",
    "# Step 6: Retrieve the vocabulary and feature matrix for Binary BoW\n",
    "vocabulary_binary_bow = vectorizer_binary_bow.get_feature_names_out()\n",
    "feature_matrix_binary_bow = X_binary_bow.toarray()\n",
    "\n",
    "print(\"\\nBinary BoW Vocabulary:\", vocabulary_binary_bow)\n",
    "print(\"\\nBinary BoW Feature Matrix:\")\n",
    "print(feature_matrix_binary_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Difference\n",
    "- **Standard BoW** captures word frequencies, which can help determine the importance of a word in a document.\n",
    "- **Binary BoW** focuses solely on word presence, ignoring frequency, making it useful when word occurrence is more important than count.\n",
    "\n",
    "\n",
    "#### Advantages and Limitations\n",
    "\n",
    "| **Advantages**                                | **Limitations**                                                                 |\n",
    "|-----------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| Simple to implement and understand            | Ignores word order and syntactic structure                                     |\n",
    "| Effective for small to medium-sized datasets  | Results in sparse and high-dimensional matrices for large vocabularies         |\n",
    "| Compatible with most machine learning models  | Does not capture semantic meaning or relationships between words               |\n",
    "| Allows for straightforward feature extraction | Out of Vocabulary (OOV) Issue leading to loss of information.                  |\n",
    "\n",
    "### Conclusion\n",
    "The Bag of Words model is a foundational NLP technique that transforms text data into numerical form based on word frequency. While it is simple and effective for certain applications, its limitations, such as ignoring word order and semantics, make it less suitable for complex tasks. More advanced methods like TF-IDF, Word2Vec, and BERT address these issues by incorporating context and semantic meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
